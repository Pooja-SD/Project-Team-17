{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing required files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from numpy.linalg import norm\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "import math \n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing and Reading data using Pandas from csv (comma seperated values) Here it is tab seperated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: is_duplicate, dtype: int64\n",
      "                  id           qid1           qid2   is_duplicate\n",
      "count  168354.000000  168354.000000  168354.000000  168354.000000\n",
      "mean    84176.500000  115204.941421  115633.193758       0.372245\n",
      "std     48599.757947   76343.737500   76745.727760       0.483405\n",
      "min         0.000000       1.000000       2.000000       0.000000\n",
      "25%     42088.250000   46894.500000   46649.500000       0.000000\n",
      "50%     84176.500000  107798.000000  108209.500000       0.000000\n",
      "75%    126264.750000  179709.500000  180905.750000       1.000000\n",
      "max    168353.000000  260809.000000  260810.000000       1.000000\n",
      "   id  qid1  qid2                                          question1  \\\n",
      "0   0     1     2  What is the step by step guide to invest in sh...   \n",
      "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
      "2   2     5     6  How can I increase the speed of my internet co...   \n",
      "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
      "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
      "\n",
      "                                           question2  is_duplicate  \n",
      "0  What is the step by step guide to invest in sh...             0  \n",
      "1  What would happen if the Indian government sto...             0  \n",
      "2  How can Internet speed be increased by hacking...             0  \n",
      "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
      "4            Which fish would survive in salt water?             0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('quora_duplicate_questions.tsv',delimiter ='\\t')\n",
    "target = df['is_duplicate']\n",
    "print(target.head(5))\n",
    "print(df.describe())\n",
    "print(df[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Converting the rows of DataFrame into list which contains sentences as each instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l_1 = df['question1'].astype(str).tolist()\n",
    "l_2 = df['question2'].astype(str).tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Removing the grammar ex: '?' etc from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def noGrammer(li):\n",
    "    l = li\n",
    "    for i in range(len(l)):\n",
    "        l[i] = re.sub('[^a-zA-Z0-9\\']', ' ', l[i])\n",
    "    return l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_1 = noGrammer(l_1)\n",
    "list_2 = noGrammer(l_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Converting each sentence into list of words using split() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168354 168354 <class 'list'> <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "text = [l.split() for l in list_1]\n",
    "text1 =[l.split() for l in list_2]\n",
    "\n",
    "print (len(text), len(text1), type(text), type(text1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Appending both the lists to create a combined csr matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336708\n"
     ]
    }
   ],
   "source": [
    "text2 = text + text1\n",
    "print (len(text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Filtering words using minimum word length as measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def filterLen(docs, minlen): \n",
    "#    r\"\"\" filter out terms that are too short. docs is a list of lists, each inner list is a document represented as a list of words minlen is the minimum length of the word to keep \"\"\" \n",
    "#    return [ [t for t in d if len(t) >= minlen ] for d in docs ] \n",
    "#docs_final = filterLen(text2, 2)\n",
    "docs_final = text2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Building CSR(Compressed Sparse Rows) matrix where each word is represented as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_matrix(docs):\n",
    "    r\"\"\" Build sparse matrix from a list of documents, \n",
    "    each of which is a list of word/terms in the document.  \n",
    "    \"\"\"\n",
    "    nrows = len(docs)\n",
    "    idx = {}\n",
    "    tid = 0\n",
    "    nnz = 0\n",
    "    for d in docs:\n",
    "        nnz += len(set(d))\n",
    "        for w in d:\n",
    "            if w not in idx:\n",
    "                idx[w] = tid\n",
    "                tid += 1\n",
    "    ncols = len(idx)\n",
    "        \n",
    "    # set up memory\n",
    "    ind = np.zeros(nnz, dtype=np.int)\n",
    "    val = np.zeros(nnz, dtype=np.double)\n",
    "    ptr = np.zeros(nrows+1, dtype=np.int)\n",
    "    i = 0  # document ID / row counter\n",
    "    n = 0  # non-zero counter\n",
    "    # transfer values\n",
    "    for d in docs:\n",
    "        cnt = Counter(d)\n",
    "        keys = list(k for k,_ in cnt.most_common())\n",
    "        l = len(keys)\n",
    "        for j,k in enumerate(keys):\n",
    "            ind[j+n] = idx[k]\n",
    "            val[j+n] = cnt[k]\n",
    "        ptr[i+1] = ptr[i] + l\n",
    "        n += l\n",
    "        i += 1\n",
    "            \n",
    "    mat = csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype=np.double)\n",
    "    mat.sort_indices()\n",
    "    \n",
    "    return mat\n",
    "\n",
    "\n",
    "def csr_info(mat, name=\"\", non_empy=False):\n",
    "    r\"\"\" Print out info about this CSR matrix. If non_empy, \n",
    "    report number of non-empty rows and cols as well\n",
    "    \"\"\"\n",
    "    if non_empy:\n",
    "        print(\"%s [nrows %d (%d non-empty), ncols %d (%d non-empty), nnz %d]\" % (\n",
    "                name, mat.shape[0], \n",
    "                sum(1 if mat.indptr[i+1] > mat.indptr[i] else 0 \n",
    "                for i in range(mat.shape[0])), \n",
    "                mat.shape[1], len(np.unique(mat.indices)), \n",
    "                len(mat.data)))\n",
    "    else:\n",
    "        print( \"%s [nrows %d, ncols %d, nnz %d]\" % (name, \n",
    "                mat.shape[0], mat.shape[1], len(mat.data)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [nrows 336708, ncols 76288, nnz 3569803]\n"
     ]
    }
   ],
   "source": [
    "mat = build_matrix(docs_final)\n",
    "csr_info(mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Converting the CSR marix into inverse document frequency matrix to make it easy for calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat1: [[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]] \n",
      "\n",
      "mat2: [[ 1.03005906  0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.        ]] \n",
      "\n",
      "mat3: [[ 0.04924313  0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# scale matrix and normalize its rows\n",
    "def csr_idf(mat, copy=False, **kargs):\n",
    "    r\"\"\" Scale a CSR matrix by idf. \n",
    "    Returns scaling factors as dict. If copy is True, \n",
    "    returns scaled matrix and scaling factors.\n",
    "    \"\"\"\n",
    "    if copy is True:\n",
    "        mat = mat.copy()\n",
    "    nrows = mat.shape[0]\n",
    "    nnz = mat.nnz\n",
    "    ind, val, ptr = mat.indices, mat.data, mat.indptr\n",
    "    # document frequency\n",
    "    df = defaultdict(int)\n",
    "    for i in ind:\n",
    "        df[i] += 1\n",
    "    # inverse document frequency\n",
    "    for k,v in df.items():\n",
    "        df[k] = np.log(nrows / float(v))  ## df turns to idf - reusing memory\n",
    "    # scale by idf\n",
    "    for i in range(0, nnz):\n",
    "        val[i] *= df[ind[i]]\n",
    "        \n",
    "    return df if copy is False else mat\n",
    "\n",
    "def csr_l2normalize(mat, copy=False, **kargs):\n",
    "    r\"\"\" Normalize the rows of a CSR matrix by their L-2 norm. \n",
    "    If copy is True, returns a copy of the normalized matrix.\n",
    "    \"\"\"\n",
    "    if copy is True:\n",
    "        mat = mat.copy()\n",
    "    nrows = mat.shape[0]\n",
    "    nnz = mat.nnz\n",
    "    ind, val, ptr = mat.indices, mat.data, mat.indptr\n",
    "    # normalize\n",
    "    for i in range(nrows):\n",
    "        rsum = 0.0    \n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            rsum += val[j]**2\n",
    "        if rsum == 0.0:\n",
    "            continue  # do not normalize empty rows\n",
    "        rsum = 1.0/np.sqrt(rsum)\n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            val[j] *= rsum\n",
    "            \n",
    "    if copy is True:\n",
    "        return mat\n",
    "mat2 = csr_idf(mat, copy=True)\n",
    "mat3 = csr_l2normalize(mat2, copy=True)\n",
    "print(\"mat1:\", mat[15,:20].todense(), \"\\n\")\n",
    "print(\"mat2:\", mat2[15,:20].todense(), \"\\n\")\n",
    "print(\"mat3:\", mat3[15,:20].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336708, 76288)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dividing the matrix into Query matrix 1 and Query matrix 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_mat1 = mat3[:168354, :]\n",
    "query_mat2 = mat3[168354:336708, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168354, 76288)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_mat2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168354, 76288)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_mat1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76288"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rows = query_mat1.shape[0]\n",
    "columns = query_mat1.shape[1]\n",
    "rows\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Taking a sample of 405 queries to find out the cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405 76288\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "s=0\n",
    "rows1 = 405 #math.ceil(rows/10000)\n",
    "column1 = columns\n",
    "print(rows1, column1)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cosine Similarity without dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(rows1):\n",
    "    for j in range(column1):\n",
    "        s+=(query_mat1[i,j] * query_mat2[i,j])\n",
    "    result.append(s)\n",
    "    s=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Sample Result of the above similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95457300276469914, 0.63548022048394803, 0.13078660827503402, 0.0, 0.24097646710963014, 0.43739767675365537, 0.0, 0.80849080877150792, 0.97973797735255241, 0.60445559582886643]\n"
     ]
    }
   ],
   "source": [
    "print(result[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_test = []\n",
    "for i in range(0,rows1):\n",
    "    if result[i]>0.55:\n",
    "        class_test.append(1) \n",
    "    else:\n",
    "         class_test.append(0)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "for i in range(0,rows1):\n",
    "    if class_test[i] == target[i]:\n",
    "        accuracy.append(1)\n",
    "    else:\n",
    "        accuracy.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64197530864197527"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
